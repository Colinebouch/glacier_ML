{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting the coordinates of the centerlines for Svalbard glaciers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the OGGM model to compute the centerline in Svalard: https://docs.oggm.org/en/latest/flowlines.html\n",
    "\n",
    "Glacier flowlines\n",
    "Computing the flowlines is the first task to run after the definition of the local map and topography.\n",
    "\n",
    "OGGM is a “flowline model”, which means that the glacier ice flow is assumed to happen along a representative “1.5D” flowline, as in the image below. “1.5D” here is used to emphasize that although glacier ice can flow only in one direction along the flowline, each point of the glacier has a geometrical width. This width means that flowline glaciers are able to match the observed area-elevation distribution of true glaciers, and can parametrize the changes in glacier width with thickness changes.\n",
    "\n",
    "Geometrical centerlines: Centerline determination\n",
    "\n",
    "Our algorithm is an implementation of the procedure described by Kienholz et al., (2014). Appart from some minor changes (mostly the choice of some parameters), we stay close to the original algorithm.\n",
    "\n",
    "The basic idea is to find the terminus of the glacier (its lowest point) and a series of centerline “heads” (local elevation maxima). The centerlines are then computed with a least cost routing algorithm minimizing both (i) the total elevation gain and (ii) the distance to the glacier terminus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/colili/anaconda3/lib/python3.8/site-packages/oggm/cfg.py:381: FutureWarning: In future versions of OGGM, the logging config WORKFLOW will no longer print ERROR or WARNING messages, but only high level information (i.e. hiding potential errors in your code but also avoiding cluttered log files for runs with many expected errors, e.g. global runs). If you want to obtain a similar logger behavior as before, set `logging_level='WARNING'`, which will print high level info as well as errors and warnings during the run. If you want to use the new behavior and suppress this warning, set `logging_level='WORKFLOW'` and `future=True`.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "2021-06-15 09:19:58: oggm.cfg: Reading default parameters from the OGGM `params.cfg` configuration file.\n",
      "2021-06-15 09:19:58: oggm.cfg: Multiprocessing switched OFF according to the parameter file.\n",
      "2021-06-15 09:19:58: oggm.cfg: Multiprocessing: using all available processors (N=8)\n",
      "/home/colili/anaconda3/lib/python3.8/site-packages/oggm/cfg.py:381: FutureWarning: In future versions of OGGM, the logging config WORKFLOW will no longer print ERROR or WARNING messages, but only high level information (i.e. hiding potential errors in your code but also avoiding cluttered log files for runs with many expected errors, e.g. global runs). If you want to obtain a similar logger behavior as before, set `logging_level='WARNING'`, which will print high level info as well as errors and warnings during the run. If you want to use the new behavior and suppress this warning, set `logging_level='WORKFLOW'` and `future=True`.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "2021-06-15 09:19:59: oggm.cfg: Reading default parameters from the OGGM `params.cfg` configuration file.\n",
      "2021-06-15 09:19:59: oggm.cfg: Multiprocessing switched OFF according to the parameter file.\n",
      "2021-06-15 09:19:59: oggm.cfg: Multiprocessing: using all available processors (N=8)\n"
     ]
    }
   ],
   "source": [
    "from oggm.utils import *\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import oggm\n",
    "import os\n",
    "from oggm import cfg, utils, workflow, tasks, graphics\n",
    "from oggm.core import inversion\n",
    "cfg.initialize(logging_level='WORKFLOW')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import calendar\n",
    "import xarray as xr\n",
    "import salem\n",
    "import pandas as pd\n",
    "import holoviews as hv\n",
    "#hv.extension('bokeh')\n",
    "import geoviews as gv\n",
    "import geoviews.tile_sources as gts\n",
    "\n",
    "# set default font size in plots\n",
    "plt.rc('font', size=16)\n",
    "\n",
    "cfg.initialize(logging_level='WORKFLOW')\n",
    "cfg.PATHS['working_dir'] = utils.gettempdir(home='True')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/colili/tmp/OGGM/'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg.PATHS['working_dir']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the area for Svalbard (zone 07)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.get_rgi_dir(version='62')  # path to the data after download\n",
    "svalbard = utils.get_rgi_region_file('07', version='62')  # Svalbard region"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test on 2 glaciers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-15 09:19:59: oggm.workflow: init_glacier_directories from prepro level 3 on 1 glaciers.\n",
      "2021-06-15 09:20:00: oggm.workflow: Execute entity task gdir_from_prepro on 1 glaciers\n",
      "2021-06-15 09:20:05: oggm.workflow: init_glacier_directories from prepro level 3 on 1 glaciers.\n",
      "2021-06-15 09:20:05: oggm.workflow: Execute entity task gdir_from_prepro on 1 glaciers\n"
     ]
    }
   ],
   "source": [
    "from oggm.utils import *\n",
    "rgi_id = []\n",
    "gdir1 = workflow.init_glacier_directories('RGI60-07.01458', from_prepro_level=3, prepro_border=80)[0]\n",
    "gdir2 = workflow.init_glacier_directories('RGI60-07.01459', from_prepro_level=3, prepro_border=80)[0]\n",
    "# centerline_tuna = write_centerlines_to_shape([gdir1, gdir2], path = '/home/colili/Documents/PhD/project_john/'+rgi_id)\n",
    "# centerline_tuna = write_centerlines_to_shape([gdir1, gdir2], filesuffix = rgi_id, path = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Access the coordinates of the centerline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_main_glacier_segment' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-423a28089568>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcenterline_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_main_glacier_segment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgdir1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mcenterline_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'geometry'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'get_main_glacier_segment' is not defined"
     ]
    }
   ],
   "source": [
    "centerline_data = get_main_glacier_segment(gdir1)\n",
    "centerline_data['geometry'].coords.xy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get centerlines in lonlat, return the main centerline, and convert the shape file to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cust_get_centerline_lonlat(gdir):\n",
    "    \"\"\"Quick n dirty solution to write the centerlines as a shapefile\"\"\"\n",
    "\n",
    "    cls = gdir.read_pickle('centerlines')\n",
    "    olist = []\n",
    "    for j, cl in enumerate(cls[::-1]):\n",
    "        mm = 1 if j == 0 else 0\n",
    "        gs = dict()\n",
    "        gs['RGIID'] = gdir.rgi_id\n",
    "        gs['LE_SEGMENT'] = np.rint(np.max(cl.dis_on_line) * gdir.grid.dx)\n",
    "        gs['MAIN'] = mm\n",
    "#         tra_func = partial(gdir.grid.ij_to_crs, crs=wgs84)\n",
    "        tra_func = partial(gdir.grid.ij_to_crs, crs=wgs84)\n",
    "        gs['geometry'] = shp_trafo(tra_func, cl.line)\n",
    "        olist.append(gs)\n",
    "\n",
    "    return olist\n",
    "\n",
    "def get_main_glacier_segment(gdir):\n",
    "    \"\"\"\n",
    "    Returns segment in gdir that is the main\n",
    "    \n",
    "    This is because there are several segments usually\n",
    "    in the data but we only want the main segment since\n",
    "    this is the centerline of the glacier\n",
    "    \n",
    "    does no error handling or correction if there\n",
    "    is no main segment\n",
    "    \"\"\"\n",
    "    for segment in cust_get_centerline_lonlat(gdir):\n",
    "        if segment['MAIN'] == 1:\n",
    "            return segment\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "def convert_shape_to_dataframe(gdir):\n",
    "    \"\"\"\n",
    "    Converts the oggm output of the centerline finder function\n",
    "    to lat and lon dataframe\n",
    "    \n",
    "    Also projects the lat and lon to UTM 33N\n",
    "    \"\"\"\n",
    "#     centerline_data = cust_get_centerline_lonlat(gdir)[0] # returns only the first\n",
    "#     centerline_data = cust_get_centerline_lonlat(gdir) # returns only the first\n",
    "    centerline_data = get_main_glacier_segment(gdir)\n",
    "    rgiid = centerline_data['RGIID']\n",
    "#     x, y = centerline_data['geometry'].coords.xy\n",
    "    p = pyproj.Proj(proj='utm', zone=33, ellps='WGS84')\n",
    "    x, y = centerline_data['geometry'].coords.xy\n",
    "    x, y = p(x, y)\n",
    "    return pd.DataFrame({'rgiid':(rgiid,)*len(x), 'x':x, 'y':y})\n",
    "\n",
    "convert_shape_to_dataframe(gdir2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply the centerline method for all glaciers in Svalbard taking there RGI-ID and save df to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gpd.read_file(svalbard)\n",
    "list(gdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "missing_glaciers = []\n",
    "\n",
    "for rgi_id in gdf['RGIId']:   #[0:10]:\n",
    "    \n",
    "    dataholder = []\n",
    "    surge = []\n",
    "    BgnDate = []\n",
    "    EndDate = []\n",
    "    CenLon = []\n",
    "    CenLat = []\n",
    "    Area = []\n",
    "    Zmin = []\n",
    "    Zmax = []\n",
    "    Zmed = []\n",
    "    Slope = []\n",
    "    Aspect=[]\n",
    "    Lmax = []\n",
    "    Status = []\n",
    "    Connect = []\n",
    "    Form = []\n",
    "    TermType = []\n",
    "    Linkages = []\n",
    "    Name = []\n",
    "    check_geom = []\n",
    "    geometry = []\n",
    "    \n",
    "    try:\n",
    "        surge.append(gdf[gdf.RGIId == rgi_id].Surging.values[0])\n",
    "        BgnDate.append(gdf[gdf.RGIId == rgi_id].BgnDate.values[0])\n",
    "        EndDate.append(gdf[gdf.RGIId == rgi_id].EndDate.values[0])\n",
    "        CenLon.append(gdf[gdf.RGIId == rgi_id].CenLon.values[0])\n",
    "        CenLat.append(gdf[gdf.RGIId == rgi_id].CenLat.values[0])\n",
    "        Area.append(gdf[gdf.RGIId == rgi_id].Area.values[0])\n",
    "        Zmin.append(gdf[gdf.RGIId == rgi_id].Zmin.values[0])\n",
    "        Zmax.append(gdf[gdf.RGIId == rgi_id].Zmax.values[0])\n",
    "        Zmed.append(gdf[gdf.RGIId == rgi_id].Zmed.values[0])\n",
    "        Slope.append(gdf[gdf.RGIId == rgi_id].Slope.values[0])\n",
    "        Aspect.append(gdf[gdf.RGIId == rgi_id].Aspect.values[0])\n",
    "        Lmax.append(gdf[gdf.RGIId == rgi_id].Lmax.values[0])\n",
    "        Status.append(gdf[gdf.RGIId == rgi_id].Status.values[0])\n",
    "        Connect.append(gdf[gdf.RGIId == rgi_id].Connect.values[0])\n",
    "        Form.append(gdf[gdf.RGIId == rgi_id].Form.values[0])\n",
    "        TermType.append(gdf[gdf.RGIId == rgi_id].TermType.values[0])\n",
    "        Linkages.append(gdf[gdf.RGIId == rgi_id].Linkages.values[0])\n",
    "        Name.append(gdf[gdf.RGIId == rgi_id].Name.values[0])\n",
    "        check_geom.append(gdf[gdf.RGIId == rgi_id].check_geom.values[0])\n",
    "        geometry.append(gdf[gdf.RGIId == rgi_id].geometry.values[0])\n",
    "\n",
    "\n",
    "        data_glaciers =  {'rgiid':rgi_id, 'Surge':surge,\\\n",
    "                          'BgnDate': BgnDate, 'EndDate':EndDate, 'CenLon':CenLon,\\\n",
    "                          'CenLat':CenLat, 'Area':Area, 'Zmin':Zmin, 'Zmax':Zmax,\\\n",
    "                          'Zmed':Zmed, 'Slope':Slope, 'Aspect':Aspect, 'Lmax':Lmax,\\\n",
    "                           'Status':Status, 'Connect':Connect, 'Form':Connect,\\\n",
    "                          'TermType':TermType, 'Linkages': Linkages, 'Name':Name, \\\n",
    "                          'check_geom': check_geom, 'geometry':check_geom}\n",
    "        single_glacier = pd.DataFrame(data_glaciers)\n",
    "\n",
    "        gdir = workflow.init_glacier_directories(rgi_id, from_prepro_level=3, prepro_border=80)[0]\n",
    "\n",
    "        centerlinedf = convert_shape_to_dataframe(gdir)\n",
    "        centerlinedf.set_index('rgiid', inplace=True)\n",
    "        single_glacier.set_index('rgiid', inplace=True)\n",
    "        combineddf = centerlinedf.join(single_glacier)\n",
    "    #     combineddf = pd.concat()\n",
    "        df = pd.concat([df, combineddf])\n",
    "    except os.error:\n",
    "        missing_glaciers.append(rgi_id)\n",
    "        pass\n",
    "\n",
    "df.to_csv('/home/colili/Documents/PhD/project_john/data_set/data_centerlines_svalbard/data_centerline_svalbard.csv')   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
