{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Authors: Peter Prettenhoer <peter.prettenhofer@gmail.com>\n",
    "\n",
    "Jake Vanderplas <vanderplas@astro.washington.edu>\n",
    "\n",
    "License: BSD Style."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn.datasets.base'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-84f293aa076e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpylab\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBunch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfetch_species_distributions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspecies_distributions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconstruct_grids\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn.datasets.base'"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "\n",
    "import numpy as np\n",
    "import pylab as pl\n",
    "\n",
    "from sklearn.datasets.base import Bunch\n",
    "from sklearn.datasets import fetch_species_distributions\n",
    "from sklearn.datasets.species_distributions import construct_grids\n",
    "from sklearn import svm, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "\n",
    "import numpy as np\n",
    "import pylab as pl\n",
    "\n",
    "from sklearn.datasets.base import Bunch\n",
    "from sklearn.datasets import fetch_species_distributions\n",
    "from sklearn.datasets.species_distributions import construct_grids\n",
    "from sklearn import svm, metrics\n",
    "\n",
    "# if basemap is available, we'll use it.\n",
    "# otherwise, we'll improvise later...\n",
    "try:\n",
    "    from mpl_toolkits.basemap import Basemap\n",
    "    basemap = True\n",
    "except ImportError:\n",
    "    basemap = False\n",
    "\n",
    "print __doc__\n",
    "\n",
    "\n",
    "def create_species_bunch(species_name,\n",
    "                         train, test,\n",
    "                         coverages, xgrid, ygrid):\n",
    "    \"\"\"\n",
    "    create a bunch with information about a particular organism\n",
    "\n",
    "    This will use the test/train record arrays to extract the\n",
    "    data specific to the given species name.\n",
    "    \"\"\"\n",
    "    bunch = Bunch(name=' '.join(species_name.split(\"_\")[:2]))\n",
    "\n",
    "    points = dict(test=test, train=train)\n",
    "\n",
    "    for label, pts in points.iteritems():\n",
    "        # choose points associated with the desired species\n",
    "        pts = pts[pts['species'] == species_name]\n",
    "        bunch['pts_%s' % label] = pts\n",
    "\n",
    "        # determine coverage values for each of the training & testing points\n",
    "        ix = np.searchsorted(xgrid, pts['dd long'])\n",
    "        iy = np.searchsorted(ygrid, pts['dd lat'])\n",
    "        bunch['cov_%s' % label] = coverages[:, -iy, ix].T\n",
    "\n",
    "    return bunch\n",
    "\n",
    "\n",
    "def plot_species_distribution(species=[\"bradypus_variegatus_0\",\n",
    "                                       \"microryzomys_minutus_0\"]):\n",
    "    \"\"\"\n",
    "    Plot the species distribution.\n",
    "    \"\"\"\n",
    "    if len(species) > 2:\n",
    "        print (\"Note: when more than two species are provided, only \"\n",
    "               \"the first two will be used\")\n",
    "\n",
    "    t0 = time()\n",
    "\n",
    "    # Load the compressed data\n",
    "    data = fetch_species_distributions()\n",
    "\n",
    "    # Set up the data grid\n",
    "    xgrid, ygrid = construct_grids(data)\n",
    "\n",
    "    # The grid in x,y coordinates\n",
    "    X, Y = np.meshgrid(xgrid, ygrid[::-1])\n",
    "\n",
    "    # create a bunch for each species\n",
    "    BV_bunch = create_species_bunch(species[0],\n",
    "                                    data.train, data.test,\n",
    "                                    data.coverages, xgrid, ygrid)\n",
    "    MM_bunch = create_species_bunch(species[1],\n",
    "                                    data.train, data.test,\n",
    "                                    data.coverages, xgrid, ygrid)\n",
    "\n",
    "    # background points (grid coordinates) for evaluation\n",
    "    np.random.seed(13)\n",
    "    background_points = np.c_[np.random.randint(low=0, high=data.Ny,\n",
    "                                                size=10000),\n",
    "                              np.random.randint(low=0, high=data.Nx,\n",
    "                                                size=10000)].T\n",
    "\n",
    "    # We'll make use of the fact that coverages[6] has measurements at all\n",
    "    # land points.  This will help us decide between land and water.\n",
    "    land_reference = data.coverages[6]\n",
    "\n",
    "    # Fit, predict, and plot for each species.\n",
    "    for i, species in enumerate([BV_bunch, MM_bunch]):\n",
    "        print \"_\" * 80\n",
    "        print \"Modeling distribution of species '%s'\" % species.name\n",
    "\n",
    "        # Standardize features\n",
    "        mean = species.cov_train.mean(axis=0)\n",
    "        std = species.cov_train.std(axis=0)\n",
    "        train_cover_std = (species.cov_train - mean) / std\n",
    "\n",
    "        # Fit OneClassSVM\n",
    "        print \" - fit OneClassSVM ... \",\n",
    "        clf = svm.OneClassSVM(nu=0.1, kernel=\"rbf\", gamma=0.5)\n",
    "        clf.fit(train_cover_std)\n",
    "        print \"done. \"\n",
    "\n",
    "        # Plot map of South America\n",
    "        pl.subplot(1, 2, i + 1)\n",
    "        if basemap:\n",
    "            print \" - plot coastlines using basemap\"\n",
    "            m = Basemap(projection='cyl', llcrnrlat=Y.min(),\n",
    "                        urcrnrlat=Y.max(), llcrnrlon=X.min(),\n",
    "                        urcrnrlon=X.max(), resolution='c')\n",
    "            m.drawcoastlines()\n",
    "            m.drawcountries()\n",
    "        else:\n",
    "            print \" - plot coastlines from coverage\"\n",
    "            pl.contour(X, Y, land_reference,\n",
    "                       levels=[-9999], colors=\"k\",\n",
    "                       linestyles=\"solid\")\n",
    "            pl.xticks([])\n",
    "            pl.yticks([])\n",
    "\n",
    "        print \" - predict species distribution\"\n",
    "\n",
    "        # Predict species distribution using the training data\n",
    "        Z = np.ones((data.Ny, data.Nx), dtype=np.float64)\n",
    "\n",
    "        # We'll predict only for the land points.\n",
    "        idx = np.where(land_reference > -9999)\n",
    "        coverages_land = data.coverages[:, idx[0], idx[1]].T\n",
    "\n",
    "        pred = clf.decision_function((coverages_land - mean) / std)[:, 0]\n",
    "        Z *= pred.min()\n",
    "        Z[idx[0], idx[1]] = pred\n",
    "\n",
    "        levels = np.linspace(Z.min(), Z.max(), 25)\n",
    "        Z[land_reference == -9999] = -9999\n",
    "\n",
    "        # plot contours of the prediction\n",
    "        pl.contourf(X, Y, Z, levels=levels, cmap=pl.cm.Reds)\n",
    "        pl.colorbar(format='%.2f')\n",
    "\n",
    "        # scatter training/testing points\n",
    "        pl.scatter(species.pts_train['dd long'], species.pts_train['dd lat'],\n",
    "                   s=2 ** 2, c='black',\n",
    "                   marker='^', label='train')\n",
    "        pl.scatter(species.pts_test['dd long'], species.pts_test['dd lat'],\n",
    "                   s=2 ** 2, c='black',\n",
    "                   marker='x', label='test')\n",
    "        pl.legend()\n",
    "        pl.title(species.name)\n",
    "        pl.axis('equal')\n",
    "\n",
    "        # Compute AUC w.r.t. background points\n",
    "        pred_background = Z[background_points[0], background_points[1]]\n",
    "        pred_test = clf.decision_function((species.cov_test - mean)\n",
    "                                          / std)[:, 0]\n",
    "        scores = np.r_[pred_test, pred_background]\n",
    "        y = np.r_[np.ones(pred_test.shape), np.zeros(pred_background.shape)]\n",
    "        fpr, tpr, thresholds = metrics.roc_curve(y, scores)\n",
    "        roc_auc = metrics.auc(fpr, tpr)\n",
    "        pl.text(-35, -70, \"AUC: %.3f\" % roc_auc, ha=\"right\")\n",
    "        print \"\\n Area under the ROC curve : %f\" % roc_auc\n",
    "\n",
    "    print \"\\ntime elapsed: %.2fs\" % (time() - t0)\n",
    "\n",
    "\n",
    "plot_species_distribution()\n",
    "pl.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
